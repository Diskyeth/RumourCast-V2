{"noir_version":"0.38.0+e784523a15c0c233a5a794f28498635b7ce86325","hash":4979584894390306709,"abi":{"parameters":[{"name":"root","type":{"kind":"field"},"visibility":"public"},{"name":"index","type":{"kind":"field"},"visibility":"private"},{"name":"path","type":{"kind":"array","length":13,"type":{"kind":"field"}},"visibility":"private"},{"name":"pub_key_x","type":{"kind":"array","length":32,"type":{"kind":"integer","sign":"unsigned","width":8}},"visibility":"private"},{"name":"pub_key_y","type":{"kind":"array","length":32,"type":{"kind":"integer","sign":"unsigned","width":8}},"visibility":"private"},{"name":"signature","type":{"kind":"array","length":64,"type":{"kind":"integer","sign":"unsigned","width":8}},"visibility":"private"},{"name":"message_hash","type":{"kind":"array","length":32,"type":{"kind":"integer","sign":"unsigned","width":8}},"visibility":"private"}],"return_type":null,"error_types":{}},"bytecode":"H4sIAAAAAAAA/+2dB5hV5bWG12bovczQy9CLKGfPnJk5g0pHAQGxYMMCAzMWbFiwoYKoWLBhQexiw4KKGE1yo8mNSW5McmOSG5PcmOTG5Pbe7401a4W9ZXFYTs5wvjWz9zOzn+ebvc93YLn+9e/1/+8+DjMB7TleKyHaHuy5llNJdO7F6pzn9Ta8PobX1/D6GV6p4ZUZXn/DG2B4Aw1vkOENNrwhhjfU8IYZ3nDDG2F45YY30vBGGd5owxtjeGMNb5zhjTe8CYY30fAmGd5BhjfZ8A42vEMMb4rhZQwvNLwKw6s0vKzhVRleteHVGF7O8GoNb6rhHWp4hxne4YY3zfCmG94Mw5tpeLMMb7bhzTG8uYZ3hOEdaXjzDG++4S0wvKMMb6HhLTK8xYZ3tOEtMbxjDO9YwzvO8I43vKWGd4LhnWh4JxneyYZ3iuEtM7xTDe80wzvd8M4wvOWGt8Lw6gxvpeGtMrx6w2swvDMN7yzDO9vwzjG81YZ3ruGdZ3jnG94Fhneh4a0xvIsM72LDu8TwLjW8tYZ3meFdbnhXGN6VhneV4a0zvKsN7xrDu9bw1hveBsO7zvA2Gt71hneD4d1oeJsM7ybDu9nwbjG8Ww1vs+HdZni3G94dhnen4d1leFsM727Du8fw7jW8+wxvq+Hdb3jbDO8Bw3vQ8B4yvIcN7xHDe9TwHjO8xw1vu+E9YXhPGt5Thve04T1jeDsM71nDe87wnje8Fwxvp+G9qLxO0Vk/f+jnDv28oZ8z9POFfq7QzxP6OUI/P+jnBv28oJ8T9POBfi7QzwP6OUDzf7m6HqmuNeePVtea6zXPa47X/D5BXWte15yu+VxzueZxzeGavzV3a97WnK35WnO15mnN0ZqfNTdrXtacrPlYc7HmYc3Bmn9nqOuZ6lpz7mx1rblW86zmWM2v89S15lXNqZpPNZdqHtUcqvlTc6fmTc2Zmi81V2qe1Byp+VFzo+ZFzYmaDzUXah7UHKj5b7m6XqGuNeetVNea6zTPaY7T/HaWuta8pjlN85nmMs1jmsM0f2nu0rylOUvzleYqzVOaozQ/aW7SvKQ5SfOR5iLNQ5qDNP+sV9cb1LXmnI3qWnON5hnNMZpfblLXmlc0p2g+0VyieURziOYPzR2aNzRnaL7QXKF5QnOE5gfNDZoXNCdoPtBcoHlAc4De/x9T14+ra73P6/1d7+t6P9f7uN6/d6hrvV/rfVrvz3pf1vtxvA+/RPseQXSeEZ0zxR3hSypWZaY6m62vqagPK8MVmYraulxVJltVV50Lc2FVrmpVRa6ysj6XzdXU1tXWZGrDbGV92FBVW9kQBesQxWlH+x+dwXn3QsUKM5nemFihfOmDiBXuOfUtPlYYX/QrNla497K0uFihflFWTKxw35f9cfdXhozjAGOH+Ybuj5ej8y75Is0dg7i88Waet0slER9di0tuv2TbGqspkVpfYzVxk8jkbRLhy4TbcHYRuTR8O3BPIcf8SiOxcjX1dQ012coVmWxDHcepbqivXFFRGzbkKjl8ZTasW1GfWZWtq6nOVucaav6wYQe0Fyr0gQaNV3CxMjrf3Z4J73aI+yrwZvAa96uqwKC4Zq6IBUByLbZh8+Mi5+gLhL3xYxiQuDNZzUndAwgHBwMJBweDCAcHgwkHB0MIBwdDCQcHwwgHB8PJZxOm4u7dRqn7tej8unzRTSVv5FP36+RP3W2N1ZRIra+xiqXu1wi3ob1O5NLwaOpGjvmLlE7q/iJh4SM+vuSZ8Jcc4n4ZeDN4jfvLqsCguC7U/XqUK5q6kXP0J4S98WMYkLjNTd0jCAcH5YSDg5GEg4NRhIOD0YSDgzGEg4OxhIODceSzCVNx926j1P2V6PyGfNFNJW/kU/cb5E/dbY3VlEitr7GKpe6vEG5De4PIpeHR1I0c85uUTup+k7DwER9f9Uz4qw5xvwa8GbzG/TVVYFBcF+p+I8oVTd3IOfpTwt74MQxI3Oam7vGEg4MJhIODiYSDg0mEg4ODCAcHkwkHBwcTDg4OIZ9NmIq7dxul7q9H57fki24qeSOfut8if+pua6ymRGp9jVUsdX+dcBvaW0QuDY+mbuSYv0HppO5vEBY+4uObngl/0yHut4A3g9e4v6UKDIrrQt1vRbmiqRs5R39G2Bs/hgGJ29zUPYVwcJAhHByEhIODCsLBQSXh4CBLODioIhwcVJPPJkzF3buNUve3o/Pb8kU3lbyRT91vkz91tzVWUyK1vsYqlrq/TbgN7W0il4ZHUzdyzN+hdFL3dwgLH/HxXc+Ev+sQ93vAm8Fr3N9TBQbFdaHut6Nc0dSNnKM/J+yNH8OAxG1u6q4hHBzkCAcHtYSDg6mEg4NDCQcHhxEODg4nHBxMI59NmIq7dxul7u9H53fki24qeSOfut8hf+pua6ymRGp9jVUsdX+fcBvaO0QuDY+mbuSYf0DppO4fEBY+4uOHngn/0CHuj4A3g9e4f6QKDIrrQt3vRLmiqRs5R39B2Bs/hgGJ29zUPZ1wcDCDcHAwk3BwMItwcDCbcHAwh3BwMJdwcHAE+WzCVNy92yh1/zg6vytfdFPJG/nU/S75U3dbYzUlUutrrGKp+8eE29DeJXJpeDR1I8f8E0ondf+EsPARHz/1TPinDnF/BrwZvMb9M1VgUFwX6n43yhVN3cg5+kvC3vgxDEjc5qbuIwkHB/MIBwfzCQcHCwgHB0cRDg4WEg4OFhEODhaTzyZMxd27jVL3z6Pze/JFN5W8kU/d75E/dbc1VlMitb7GKpa6f064De09IpeGR1M3csy/oHRS9y8ICx/x8UvPhH/pEPdXwJvBa9y/UgUGxXWh7veiXNHUjZyjvyLsjR/DgMSdGV13o31/tLD+gWf6xzDofxymv2VV/490/fFePnSg7jFwvExbvLZ4jR05cDx0fm3xWl+8X7PeZ/2G9VvWX7P+hvW3rL9j/T3rH1j/yPon1j+z/oX1r6x/Y/076z9Y/8n6L9Z/s/6H9b+s/2P9P+3/SQyaFX4NrEn8CdHvWB+wPmR9xPqY9Qnr03gAwb4PxfLn49+3EXsfGN6HhveR4X1seJ8Y3qeGJ18659W8i2PNi2WT3wFi1TfIkQk/AMWSMX4IibWnXh8VH6sifnj9uNhY2b0Pwp8UFyujH6o/LSZWxb4P6HIPg+7VjPf68z7h15+Ak2zHKmG1Z3VgdWR1kt421p8g2H8daGd4JYbX3vA6GF5Hw+tkeJ2bYf15n3DrTxDg1p92AW79KQlw60/7ALf+dAhw60/HALf+dApw60/nFK0/vyH8+tOFk+zK6sbqzurB6snqxeptrD9djHWgq+F1M7zuhtfD8HoaXi/D690M64+uebHrTxfg+tMVuP50A64/3YHrTw/g+tMTuP70Aq4/vVO0/vyW8OtPH06yL6sfq5RVxurPGsAaaKw/fYx1oK/h9TO8UsMrM7z+hjfA8AY2w/qja17s+tMHuP70Ba4//YDrTylw/SkDrj/9gevPAOD6MzBF60+Ai5XpEcUZxEEHs4awhrKGsYazRrDKWSNZo1ijWWNYY4M9n3PpdWBQ8NlHRZ95gw1viOENNbxhhjfc8EYYXrnhjTS8UYY32vDGGN7YYO/cxkdPx7kudt0bBFv3GhoG42KtGoKLVTsUFyscBotVHw6HxVoZjoDFyoXlwL1wJCpWfSYchYq1MhOORsXKZcIxqFjc22OBe05zflNJO1ysfb6pZFzgmPC4AB93fIBbnL3GPV5VGBTXJVfZnCTXkry4Sdj04ljI+Z6Aa/6Q1FFW6LyEhQXvUFieBUXrWOiYC4jWqfD6/dFoTfrw849E69K0eW00Wtem3iONROvW9Pvtc6N1P5B793Oi9TiwPjCj9TzQnjKi9Trw/twvWlEfbuVF61PcurFPtL7FrkEqWr/i17PPopUi1sYoWhlmnf1DtP6oNZujDQCu/wOB+9LEwJcTEPv5+AD/3eJITpgEriF6rBIPmGMoLDMxwM/1QSmoI5LjpIaTHOo4GVzH+EDneXBK8jzkwPOsyDckt36s9ipXue8/ia4nq+uD1fUh0XX896bwawkmnxhWBHv85vxQoAQXa58PBSoDx4QrHT4UyCb8QwEZdzYlHwrIp8xZhw8FBgPnCDnfVeAPBdAb3vhoo0eNV+JNcYC5KcAcqxMOxHGPoGuI7JGahIOcrC/AHEPp42oHkMuloI7INUxqWONQx9oACyv5AJdToFZbIMBN5deHsg5jHd4CANeesDWJj2mBY8LTHABuesIBTsY9PSUAJ/9rf7oDwA0BzhFyvmckHOCy0caEGq/Em+oAH1OBOc5MOMDFPYKuIbJHZiUcPGRNBOYYSh/PdACP2SmoI3INkxrOcqjjHGeAm61AbU6BADeXXx/BOpI1rwUArgNhaxIf8wPHhOc7ANyChAOcjHtBSgBOvp9ygQPADQXOEXK+j0o4wE2PNibUeCXeXAf4mAvMcWHCAS7uEXQNkT2yKOHgIWsiMMdQ+nihA3gsTkEdkWuY1HCRQx2Pdga4xQrUji4Q4Jbw62NYx7KOawGA60jYmsTH8YFjwsc7ANzShAOcjHtpSgBO/hHLUgeAGwacI+R8n5BwgFsQbUyo8Uq8JQ7wsQSY44kJB7i4R9A1RPbISQkHD1kTgTmG0scnOoDHySmoI3INkxqe5FDHU5wB7mQFaqcUCHDL+PWprNNYp7cAwHUibE3i44zAMeEzHABuecIBTsa9PCUAJ/9yeLkDwA0HzhFyvlckHOCWRhsTarwSb5kDfCwD5liXcICLewRdQ2SPrEw4eMiaCMwxlD6ucwCPVSmoI3INkxqudKhjvTPArVKgVl8gwDXw6zNZZ7HObgGA60zYmsTHOYFjwuc4ANzqhAOcjHt1SgBOflzLageAGwGcI+R8n5twgFsebUyo8Uq8Bgf4aADmeF7CAS7uEXQNkT1yfsLBQ9ZEYI6h9PF5DuBxQQrqiFzDpIbnO9TxQmeAu0CB2oUFAtwafn0R62LWJS0AcF0IW5P4uDRwTPhSB4Bbm3CAk3GvTQnAlQd7ckUDXDlwjpDzfVnCAW51tDGhxivx1jjAxxpgjpcnHODiHkHXENkjVyQcPGRNBOYYSh9f7gAeV6agjsg1TGp4hUMdr3IGuCsVqF1VIMCt49dXs65hXdsCANeVsDWJj/WBY8LrHQBuQ8IBTsa9ISUAJz+YeIMDwI0EzhFyvq9LOMCtjTYm1Hgl3joH+FgHzHFjwgEu7hF0DZE9cn3CwUPWRGCOofTxRgfwuCEFdUSuYVLD6x3qeKMzwN2gQO3GAgFuE7++iXUz65YWALhuhK1JfNwaOCZ8qwPAbU44wMm4N6cE4OS3QWx2ALhRwDlCzvdtCQe4DdHGhBqvxNvkAB+bgDnennCAi3sEXUNkj9yRcPCQNRGYYyh9fLsDeNyZgjoi1zCp4R0OdbzLGeDuVKB2V4EAt4Vf3826h3VvCwBcd8LWJD7uCxwTvs8B4LYmHOBk3FtTAnDyK7i2OgDcaOAcIef7/oQD3OZoY0KNV+JtcYCPLcActyUc4OIeQdcQ2SMPJBw8ZE0E5hhKH29zAI8HU1BH5BomNXzAoY4POQOczFMMag8FhQHcw/z6EdajrMeC5ge4HoStSXw8HjgmLMHRcbcHyQY4Gfd2VWFQXJdc5feeSq5ogBsDnCPkfD8RJBvgBBS2Accr8WThQuf5MDDHJwPfHkHcy9sdaojskaeCZIOHrInAHEPp4ycD/Fw/nYI6ItcwqeFTDnV8JsDCSj7APa1A7ZkCAW4Hv36W9Rzr+RYAuJ6ErUl8vBA4JvyCA8DtTDjAybh3pgTg5JfN73QAuLHAOULO94sJB7jt0caEGq/E2+EAHzuAOb6UcICLewRdQ2SPvJxw8JA1EZhjKH38kgN47EpBHZFrmNTwZYc6vuIMcLsUqL1SIMDt5tevsr7Aei3Y67cDj31ndG+i5kji7XZYf5Bj3g2e73huXlRzLuMvob3gLT8TUX6sjvzLbPnHPfL9ofItBvIptTzoSK/0YvVm9WH1je6jUlYZqz9rAGsgaxBrMGsIayhrGGs4awSrnDWSNYo1mjWGNZY1jjWeNYE1kTWJdRBrstyHcv+xpkg9WFLsCqkzK8uqYlWzalg5Vi1rKutQ1mGsw1nTWNOjOZrJmsWazZrDmss6gnUkax5rPmsB6yjWQtYi1mLW0awlrGNYx7KOYx3PWso6gXUi6yTWyaxTWMtYp7JOY53OOoO1nLWCVcdayVrFqmc1sM5kncU6m3UOazXrXNZ5rPNZF7AuZK1hXcS6mHUJ61LWWtZlrMtZV7CuZF3FWse6mnUN61rWetYG1nWsjazrWTewbmRtYt3Eupl1C+tW1mbWbazbWXew7mTdxdrCupt1D+te1n2sraz7WdtYD7AeZD3Eepj1COtR1mOsx1nbWU+wnmQ9xXqa9QxrB+tZ1nOs51kvsHbSnnvXejD87IgbunN07hKdu0Zn+cvAX6BcEcfv5hM/08kYY1d13e1zxt/e+HvB57xul3du7M829lTew3gvjtnP8LrknUtVPGANwzh+mU98c45K1XVZ3jh1nWeAcojjxQ+dHWj/o13ee/Gfze+VAJ9fmJ9LifHfig99r8Tv/x7mVG3OfhwBAA==","debug_symbols":"7Z3dahtNDIbvxcc5mJE0f7mVj1KcxCkGYwfH+aCE3HsdNxu7ZHEPpmhfVjqrk/GieRr0PjLM+HXxsLp7+fF9vX3cPS9u/3tdbHb3y8N6tz2+el3EHE4/fH5abt9fPx+W+8PiVjjeLFbbh+O/Wn27WTyuN6vFbW5vN1+WksjHUkrnpYVGlrYWPpbGUNp5Lb99uzlWEv9dJTVdVnJ6OnU+nQN/LGWK1/cZiWnYKOV0udGR59aYhwfXXD4XUx17co11eHLlcxlUfm+SLWxSLGwyWdhktrDJYmGT1cImm4FNlmBhk9HCJi0YT7FgPEUsbNKC8RQLxlMsGE+xYDzFgvFUC8ZTLRhPtWA81YLxVLGwSQvGUy0YT7VgPNWC8VQLxtMsGE+zYDzNgvE0C8bTxMImLRhPs2A8zYLxNAvG0wwYDwUDxkPBgPFQMGA8FAwYDwWxsEkDxkPBgPFQMGA8FAwYDwULxhMtGE+0YDzRgvFEC8YTxcImLRhPtGA80YLxRAvGEy0YD1kwHrJgPGTBeMiC8ZBY2KQF4yELxkMWjIcsGA9ZMB62YDxswXjYgvGwBeNhsbBJC8bDFoyHLRgPWzAetmA8YsF4xILxyCyMh2oaFlMt8mWTszAe5jjc28RM+XKTI0Qap4FISxf/7XlkcQp1QJFCa5eLT/jE8fXgm4WlTYdvFv43Hb5ZmOV0+GbhrNPhm4UNT4YvzcKzp8M3C4OfDt8sZoPp8PnU0YVPHF8PPp86uvD51NGFz6eOLnw+dXTh86mjB1/2qaMLn08dXfh86ujC51NHFz5xfD34fOrowudTRxc+nzq68PnU0YXPp44efPP4xovp8PnU0YXPp44ufD51dOETx9eDz6eOLnw+dXTh86mjC59PHV34fOrowTePb52ZDp9PHV34fOrowjc6daTUhve8g7iGT/JwNkbqeZNVRpZmGcrOmc/w2u9CBKWQhFJIRimkoBRSUQppIIWMf//JFIVElEIIpRCUztpQOmtD6awNpbM2lM7aFDtrqcNTa4hfCmkYhXAIKIUodtYWBldssX0phFAKYZRCFDtrDDzMKTHkP/5KRhbnoerY/lICt89Jic9LeWyiOc5aw86Ous7XF8da82cNIf1lcfx8coylXi4+cU7OWYVzds4qnItzVuFcnbMKZxRpiyjSFiNKISjSFlGkLQpKIW41Kt0putXocHar0eEM8lkNR5TYJ5TYJ5TPaggl9gkl9sk/q1HpTuRWo8PZrUaHc0HJFpTYJ5TY5wCSLYwS+4wS+8zenTS6E7vV6HB2q9HhnFGyBSX2GSX2uYFki6DEvqDEvpB3J43uJG41OpzFOatwTiDZIiixLyixLxUlW1BiP6HEforenTS6U3Kr0eHsVqPDWUCyJaHEfkKJ/VRQsgUl9hNK7Ofg3UmjO2W3Gh3ObjU6nBkkWzJK7GeU2M8ZJVtQYj+jxH5u3p00ulNxq9Hh7Fajw5lAsqWgxH5Bif2SQLKloMR+QYn94ucTdbqTW40K5+pWo8MZ5XRpRYn9ihL7mtfYXc2WihL7FSX2q59P1OlObjU6nN1qVDg3lNOlDSX2G0rsN5TTpZp3LF4vBCX2m59P1OlObjU6nN1qdDiDnC4VlAtAJYDEvqBcACooF4BKEJRC/HyiRncSvyFTibNbjQ5nkNOlgnKFpKBcISkR5HSpoFwhKShXSIrmFZKWu5PfkKnE2a1Gh3Ov1SQeviUsyR+cvx1f3O3Xm836x/fN7n55WO+2z8c3Hn/8/3K/Xt5tVh8vH1+29xe/Pfx8Gn4zvP9pv7tfPbzsV+9POv3u+Phf","file_map":{"26":{"source":"pub mod bn254;\nuse crate::runtime::is_unconstrained;\nuse bn254::lt as bn254_lt;\n\nimpl Field {\n    /// Asserts that `self` can be represented in `bit_size` bits.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{bit_size}`.\n    // docs:start:assert_max_bit_size\n    pub fn assert_max_bit_size<let BIT_SIZE: u32>(self) {\n        // docs:end:assert_max_bit_size\n        assert(BIT_SIZE < modulus_num_bits() as u32);\n        self.__assert_max_bit_size(BIT_SIZE);\n    }\n\n    #[builtin(apply_range_constraint)]\n    fn __assert_max_bit_size(self, bit_size: u32) {}\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_le_bits)]\n    // docs:start:to_le_bits\n    pub fn to_le_bits<let N: u32>(self: Self) -> [u1; N] {}\n    // docs:end:to_le_bits\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_be_bits)]\n    // docs:start:to_be_bits\n    pub fn to_be_bits<let N: u32>(self: Self) -> [u1; N] {}\n    // docs:end:to_be_bits\n\n    /// Decomposes `self` into its little endian byte decomposition as a `[u8;N]` array\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_le_bytes\n    pub fn to_le_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_le_bytes\n        // Compute the byte decomposition\n        let bytes = self.to_le_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[N - 1 - i] != p[N - 1 - i]) {\n                        assert(bytes[N - 1 - i] < p[N - 1 - i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    /// Decomposes `self` into its big endian byte decomposition as a `[u8;N]` array of length required to represent the field modulus\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_be_bytes\n    pub fn to_be_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_be_bytes\n        // Compute the byte decomposition\n        let bytes = self.to_be_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_be_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[i] != p[i]) {\n                        assert(bytes[i] < p[i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    // docs:start:to_le_radix\n    pub fn to_le_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            crate::assert_constant(radix);\n        }\n        self.__to_le_radix(radix)\n    }\n    // docs:end:to_le_radix\n\n    // docs:start:to_be_radix\n    pub fn to_be_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            crate::assert_constant(radix);\n        }\n        self.__to_be_radix(radix)\n    }\n    // docs:end:to_be_radix\n\n    // `_radix` must be less than 256\n    #[builtin(to_le_radix)]\n    fn __to_le_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    #[builtin(to_be_radix)]\n    fn __to_be_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    // Returns self to the power of the given exponent value.\n    // Caution: we assume the exponent fits into 32 bits\n    // using a bigger bit size impacts negatively the performance and should be done only if the exponent does not fit in 32 bits\n    pub fn pow_32(self, exponent: Field) -> Field {\n        let mut r: Field = 1;\n        let b: [u1; 32] = exponent.to_le_bits();\n\n        for i in 1..33 {\n            r *= r;\n            r = (b[32 - i] as Field) * (r * self) + (1 - b[32 - i] as Field) * r;\n        }\n        r\n    }\n\n    // Parity of (prime) Field element, i.e. sgn0(x mod p) = 0 if x `elem` {0, ..., p-1} is even, otherwise sgn0(x mod p) = 1.\n    pub fn sgn0(self) -> u1 {\n        self as u1\n    }\n\n    pub fn lt(self, another: Field) -> bool {\n        if crate::compat::is_bn254() {\n            bn254_lt(self, another)\n        } else {\n            lt_fallback(self, another)\n        }\n    }\n\n    /// Convert a little endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_le_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n\n    /// Convert a big endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_be_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[N - 1 - i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n}\n\n#[builtin(modulus_num_bits)]\npub comptime fn modulus_num_bits() -> u64 {}\n\n#[builtin(modulus_be_bits)]\npub comptime fn modulus_be_bits() -> [u1] {}\n\n#[builtin(modulus_le_bits)]\npub comptime fn modulus_le_bits() -> [u1] {}\n\n#[builtin(modulus_be_bytes)]\npub comptime fn modulus_be_bytes() -> [u8] {}\n\n#[builtin(modulus_le_bytes)]\npub comptime fn modulus_le_bytes() -> [u8] {}\n\n/// An unconstrained only built in to efficiently compare fields.\n#[builtin(field_less_than)]\nunconstrained fn __field_less_than(x: Field, y: Field) -> bool {}\n\npub(crate) unconstrained fn field_less_than(x: Field, y: Field) -> bool {\n    __field_less_than(x, y)\n}\n\n// Convert a 32 byte array to a field element by modding\npub fn bytes32_to_field(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..16 {\n        high = high + (bytes32[15 - i] as Field) * v;\n        low = low + (bytes32[16 + 15 - i] as Field) * v;\n        v = v * 256;\n    }\n    // Abuse that a % p + b % p = (a + b) % p and that low < p\n    low + high * v\n}\n\nfn lt_fallback(x: Field, y: Field) -> bool {\n    if is_unconstrained() {\n        unsafe {\n            field_less_than(x, y)\n        }\n    } else {\n        let x_bytes: [u8; 32] = x.to_le_bytes();\n        let y_bytes: [u8; 32] = y.to_le_bytes();\n        let mut x_is_lt = false;\n        let mut done = false;\n        for i in 0..32 {\n            if (!done) {\n                let x_byte = x_bytes[32 - 1 - i] as u8;\n                let y_byte = y_bytes[32 - 1 - i] as u8;\n                let bytes_match = x_byte == y_byte;\n                if !bytes_match {\n                    x_is_lt = x_byte < y_byte;\n                    done = true;\n                }\n            }\n        }\n        x_is_lt\n    }\n}\n\nmod tests {\n    use super::field_less_than;\n\n    #[test]\n    // docs:start:to_be_bits_example\n    fn test_to_be_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_be_bits();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 1, 0]);\n    }\n    // docs:end:to_be_bits_example\n\n    #[test]\n    // docs:start:to_le_bits_example\n    fn test_to_le_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_le_bits();\n        assert_eq(bits, [0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bits_example\n\n    #[test]\n    // docs:start:to_be_bytes_example\n    fn test_to_be_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_be_bytes();\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_bytes_example\n\n    #[test]\n    // docs:start:to_le_bytes_example\n    fn test_to_le_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_le_bytes();\n        assert_eq(bytes, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_bytes_example\n\n    #[test]\n    // docs:start:to_be_radix_example\n    fn test_to_be_radix() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_be_radix(256);\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_radix_example\n\n    #[test]\n    // docs:start:to_le_radix_example\n    fn test_to_le_radix() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_le_radix(256);\n        assert_eq(bytes, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_radix_example\n\n    #[test]\n    unconstrained fn test_field_less_than() {\n        assert(field_less_than(0, 1));\n        assert(field_less_than(0, 0x100));\n        assert(field_less_than(0x100, 0 - 1));\n        assert(!field_less_than(0 - 1, 0));\n    }\n}\n","path":"std/field/mod.nr"},"27":{"source":"use crate::runtime::is_unconstrained;\n\nglobal BLOCK_SIZE_IN_BYTES: u32 = 136; //(1600 - BITS * 2) / WORD_SIZE;\nglobal WORD_SIZE: u32 = 8; // Limbs are made up of u64s so 8 bytes each.\nglobal LIMBS_PER_BLOCK: u32 = BLOCK_SIZE_IN_BYTES / WORD_SIZE;\nglobal NUM_KECCAK_LANES: u32 = 25;\n\n#[foreign(keccakf1600)]\nfn keccakf1600(input: [u64; 25]) -> [u64; 25] {}\n\n#[no_predicates]\npub(crate) fn keccak256<let N: u32>(input: [u8; N], message_size: u32) -> [u8; 32] {\n    assert(N >= message_size);\n\n    // Copy input to block bytes. For that we'll need at least input bytes (N)\n    // but we want it to be padded to a multiple of BLOCK_SIZE_IN_BYTES.\n    let mut block_bytes = [0; ((N / BLOCK_SIZE_IN_BYTES) + 1) * BLOCK_SIZE_IN_BYTES];\n    if is_unconstrained() {\n        for i in 0..message_size {\n            block_bytes[i] = input[i];\n        }\n    } else {\n        for i in 0..N {\n            if i < message_size {\n                block_bytes[i] = input[i];\n            }\n        }\n    }\n\n    //1. format_input_lanes\n    let max_blocks = (N + BLOCK_SIZE_IN_BYTES) / BLOCK_SIZE_IN_BYTES;\n    //maximum number of bytes to hash\n    let real_max_blocks = (message_size + BLOCK_SIZE_IN_BYTES) / BLOCK_SIZE_IN_BYTES;\n    let real_blocks_bytes = real_max_blocks * BLOCK_SIZE_IN_BYTES;\n\n    block_bytes[message_size] = 1;\n    block_bytes[real_blocks_bytes - 1] = 0x80;\n\n    // populate a vector of 64-bit limbs from our byte array\n    let mut sliced_buffer =\n        [0; (((N / BLOCK_SIZE_IN_BYTES) + 1) * BLOCK_SIZE_IN_BYTES) / WORD_SIZE];\n    for i in 0..sliced_buffer.len() {\n        let limb_start = WORD_SIZE * i;\n\n        let mut sliced = 0;\n        let mut v = 1;\n        for k in 0..WORD_SIZE {\n            sliced += v * (block_bytes[limb_start + k] as Field);\n            v *= 256;\n        }\n\n        sliced_buffer[i] = sliced as u64;\n    }\n\n    //2. sponge_absorb\n    let mut state: [u64; NUM_KECCAK_LANES] = [0; NUM_KECCAK_LANES];\n    // When in an unconstrained runtime we can take advantage of runtime loop bounds,\n    // thus allowing us to simplify the loop body.\n    if is_unconstrained() {\n        for i in 0..real_max_blocks {\n            if (i == 0) {\n                for j in 0..LIMBS_PER_BLOCK {\n                    state[j] = sliced_buffer[j];\n                }\n            } else {\n                for j in 0..LIMBS_PER_BLOCK {\n                    state[j] = state[j] ^ sliced_buffer[i * LIMBS_PER_BLOCK + j];\n                }\n            }\n            state = keccakf1600(state);\n        }\n    } else {\n        // `real_max_blocks` is guaranteed to at least be `1`\n        // We peel out the first block as to avoid a conditional inside of the loop.\n        // Otherwise, a dynamic predicate can cause a blowup in a constrained runtime.\n        for j in 0..LIMBS_PER_BLOCK {\n            state[j] = sliced_buffer[j];\n        }\n        state = keccakf1600(state);\n        for i in 1..max_blocks {\n            if i < real_max_blocks {\n                for j in 0..LIMBS_PER_BLOCK {\n                    state[j] = state[j] ^ sliced_buffer[i * LIMBS_PER_BLOCK + j];\n                }\n                state = keccakf1600(state);\n            }\n        }\n    }\n\n    //3. sponge_squeeze\n    let mut result = [0; 32];\n    for i in 0..4 {\n        let lane = state[i] as Field;\n        let lane_le: [u8; 8] = lane.to_le_bytes();\n        for j in 0..8 {\n            result[8 * i + j] = lane_le[j];\n        }\n    }\n    result\n}\n\nmod tests {\n    use super::keccak256;\n\n    #[test]\n    fn smoke_test() {\n        let input = [0xbd];\n        let result = [\n            0x5a, 0x50, 0x2f, 0x9f, 0xca, 0x46, 0x7b, 0x26, 0x6d, 0x5b, 0x78, 0x33, 0x65, 0x19,\n            0x37, 0xe8, 0x05, 0x27, 0x0c, 0xa3, 0xf3, 0xaf, 0x1c, 0x0d, 0xd2, 0x46, 0x2d, 0xca,\n            0x4b, 0x3b, 0x1a, 0xbf,\n        ];\n        assert_eq(keccak256(input, input.len()), result);\n    }\n\n    #[test]\n    fn hash_hello_world() {\n        let input = \"Hello world!\".as_bytes();\n        let result = [\n            0xec, 0xd0, 0xe1, 0x8, 0xa9, 0x8e, 0x19, 0x2a, 0xf1, 0xd2, 0xc2, 0x50, 0x55, 0xf4, 0xe3,\n            0xbe, 0xd7, 0x84, 0xb5, 0xc8, 0x77, 0x20, 0x4e, 0x73, 0x21, 0x9a, 0x52, 0x3, 0x25, 0x1f,\n            0xea, 0xab,\n        ];\n        assert_eq(keccak256(input, input.len()), result);\n    }\n\n    #[test]\n    fn var_size_hash() {\n        let input = [\n            189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n            206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n            223,\n        ];\n        let result = [\n            226, 37, 115, 94, 94, 196, 72, 116, 194, 105, 79, 233, 65, 12, 30, 94, 181, 131, 170,\n            219, 171, 166, 236, 88, 143, 67, 255, 160, 248, 214, 39, 129,\n        ];\n        assert_eq(keccak256(input, 13), result);\n    }\n\n    #[test]\n    fn hash_longer_than_136_bytes() {\n        let input = \"123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789\"\n            .as_bytes();\n        assert(input.len() > 136);\n\n        let result = [\n            0x1d, 0xca, 0xeb, 0xdf, 0xd9, 0xd6, 0x24, 0x67, 0x1c, 0x18, 0x16, 0xda, 0xd, 0x8a, 0xeb,\n            0xa8, 0x75, 0x71, 0x2c, 0xc, 0x89, 0xe0, 0x25, 0x2, 0xe8, 0xb6, 0x5e, 0x16, 0x5, 0x55,\n            0xe4, 0x40,\n        ];\n        assert_eq(keccak256(input, input.len()), result);\n    }\n}\n","path":"std/hash/keccak.nr"},"28":{"source":"pub mod poseidon;\npub mod poseidon2;\npub mod keccak;\npub mod sha256;\npub mod sha512;\n\nuse crate::default::Default;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\nuse crate::uint128::U128;\n\n// Kept for backwards compatibility\npub use sha256::{digest, sha256, sha256_compression, sha256_var};\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n#[foreign(blake3)]\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars)[0]\n}\n\n#[field(bn254)]\n#[inline_always]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Same as from_field but:\n// does not assert the limbs are 128 bits\n// does not assert the decomposition does not overflow the EmbeddedCurveScalar\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn hash_to_field(inputs: [Field]) -> Field {\n    let mut sum = 0;\n\n    for input in inputs {\n        let input_bytes: [u8; 32] = input.to_le_bytes();\n        sum += crate::field::bytes32_to_field(blake2s(input_bytes));\n    }\n\n    sum\n}\n\n// docs:start:keccak256\npub fn keccak256<let N: u32>(input: [u8; N], message_size: u32) -> [u8; 32]\n// docs:end:keccak256\n{\n    crate::hash::keccak::keccak256(input, message_size)\n}\n\n#[foreign(poseidon2_permutation)]\npub fn poseidon2_permutation<let N: u32>(_input: [Field; N], _state_length: u32) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: StructDefinition) -> Quoted {\n    let name = quote { Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: std::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher<H>\nwhere\n    H: Hasher,\n{\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher<H> for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl Hash for U128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self.lo as Field);\n        H::write(state, self.hi as Field);\n    }\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n","path":"std/hash/mod.nr"},"33":{"source":"use crate::default::Default;\nuse crate::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        if message_size == N {\n            Poseidon2::hash_internal(input, N, false)\n        } else {\n            Poseidon2::hash_internal(input, message_size, true)\n        }\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::hash::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(\n        input: [Field; N],\n        in_len: u32,\n        is_variable_length: bool,\n    ) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n","path":"std/hash/poseidon2.nr"},"69":{"source":"use dep::std::hash::poseidon2::Poseidon2::hash;\nuse lib::ecrecover;\nuse merkle_tree::merkle::MerkleTree;\n\nfn poseidon2_hasher(leaves: [Field; 2]) -> Field {\n    hash([leaves[0], leaves[1]], 2)\n}\n\nfn main(\n    // Tree Data\n    root: pub Field,\n    index: Field,\n    path: [Field; 13],\n    // Signature Data\n    pub_key_x: [u8; 32],\n    pub_key_y: [u8; 32],\n    signature: [u8; 64],\n    message_hash: [u8; 32],\n) {\n    let address = ecrecover::ecrecover(pub_key_x, pub_key_y, signature, message_hash);\n    let mt = MerkleTree::from(root, poseidon2_hasher);\n    mt.membership(address, index, path);\n}\n\n#[test]\nfn test_main() {\n    let signature = [\n        0x2d, 0x37, 0xb1, 0x66, 0x31, 0xb6, 0x7c, 0xbe, 0x79, 0xe8, 0xb1, 0x15, 0xcd, 0xa1, 0xee,\n        0x74, 0xdd, 0xe8, 0x49, 0x2b, 0xee, 0xf9, 0xfa, 0xc0, 0x74, 0x67, 0x77, 0xc4, 0x63, 0xe0,\n        0xc8, 0xcc, 0x5c, 0xfd, 0x2c, 0xea, 0x5f, 0x1e, 0x2e, 0x6d, 0x88, 0x99, 0xe4, 0xfe, 0x33,\n        0xab, 0x70, 0x9a, 0x44, 0x9e, 0x26, 0x2c, 0xc9, 0xfc, 0x56, 0xc3, 0xd6, 0x3b, 0x78, 0x9d,\n        0x99, 0x27, 0x09, 0x54,\n    ];\n    let message_hash = [\n        0x9d, 0x44, 0x7d, 0x95, 0x6f, 0x18, 0xf0, 0x6e, 0xfc, 0x4e, 0x1f, 0xa2, 0xb7, 0x15, 0xe6,\n        0xa4, 0x6f, 0xe6, 0x80, 0xd3, 0xd3, 0x5e, 0x1e, 0xbe, 0x90, 0xb9, 0xd5, 0x6a, 0xd1, 0xed,\n        0xdc, 0xa1,\n    ];\n    let pub_key_x = [\n        0x12, 0x09, 0x76, 0x95, 0x85, 0xe7, 0xea, 0x6b, 0x1d, 0x48, 0xfb, 0x8e, 0x7a, 0x49, 0xad,\n        0x4a, 0x68, 0x7f, 0x3f, 0x21, 0x9c, 0x80, 0x2b, 0x16, 0x71, 0x32, 0xb3, 0x45, 0x6a, 0xd8,\n        0xd2, 0xe4,\n    ];\n    let pub_key_y = [\n        0x73, 0x32, 0x84, 0xca, 0x26, 0x7f, 0x3c, 0x5e, 0x6f, 0xa7, 0x5b, 0xad, 0xe8, 0x23, 0xfd,\n        0xab, 0xd5, 0xb4, 0xb6, 0xa9, 0x13, 0x85, 0xd1, 0xa6, 0xde, 0xd7, 0x6c, 0xb5, 0x5d, 0x73,\n        0x61, 0x1c,\n    ];\n    let root = 0x16f60110b4bb93763c78ee8027ea5b25a17d707be4579548985cf90e63ed5e29;\n    let index = 6120;\n    let path = [\n        0x0000000000000000000000008b80f56a65b63ca6b57230b6b81662100f77eaff,\n        0x0b348372e4472da3b514e554f824b6d637ef8555feda3e9b7d7a3ef2bd919d79,\n        0x1002d430eceed6dbf122bf2a39a705bc3df3a805b41cd81a780b59b268085e8c,\n        0x1c8c082cf3df9bf4a654a3528827f3a51f1a6869f7fce81fe5d28508af8bb229,\n        0x2c152090695fd3ef9c039f1726148e4b2677a75601ecacecbeb6a0516283a681,\n        0x01680f7cd645b0cf36226d3e1c53dd1cbbda5fd1fefdae98787e29a813cd2451,\n        0x2c2a9f3ad71f1ac332951921bdd878f7f9632448200ee849fcf0957609f98ebe,\n        0x1053163671855ddbf2119efd971ea1fc40062de43fc12d1686258279be99788d,\n        0x29bb8eb0894287b4da3fd3b4f8b9df9335802e682cdcafac7610f9cce1b9c4aa,\n        0x178619abcee2d93deaaedddd1892ec20036c0617b3ef0e27df4e6d311a86c43f,\n        0x276320588150af5b861533b94d9badd08e71ad805622b46a5e0d92291e9e4440,\n        0x08ecbb5f7f8d918280cdab0fa68b6acbac5fdab27935982bb47260e38648a4d1,\n        0x0bf2db0394f50216048c7df7a482b31d728d0a7e17a0114228d05387d49598a9,\n    ];\n    main(\n        root,\n        index,\n        path,\n        pub_key_x,\n        pub_key_y,\n        signature,\n        message_hash,\n    );\n}\n","path":"/Users/kartik/projects/anoncast/packages/zk/circuits/merkle-membership/src/main.nr"},"72":{"source":"mod secp256k1;\n\npub fn ecrecover(\n    pub_key_x: [u8; 32],\n    pub_key_y: [u8; 32],\n    signature: [u8; 64], // clip v value\n    hashed_message: [u8; 32],\n) -> Field {\n    let key = secp256k1::PubKey::from_xy(pub_key_x, pub_key_y);\n\n    assert(key.verify_sig(signature, hashed_message));\n    let addr = key.to_eth_address();\n\n    addr\n}\n\n#[test]\nfn test_ecrecover() {\n    let pub_key_x = [\n        131, 24, 83, 91, 84, 16, 93, 74, 122, 174, 96, 192, 143, 196, 95, 150, 135, 24, 27, 79, 223,\n        198, 37, 189, 26, 117, 63, 167, 57, 127, 237, 117,\n    ];\n    let pub_key_y = [\n        53, 71, 241, 28, 168, 105, 102, 70, 242, 243, 172, 176, 142, 49, 1, 106, 250, 194, 62, 99,\n        12, 93, 17, 245, 159, 97, 254, 245, 123, 13, 42, 165,\n    ];\n    let signature = [\n        57, 17, 112, 239, 241, 30, 64, 157, 170, 50, 85, 145, 156, 69, 226, 85, 147, 164, 10, 82,\n        71, 93, 42, 132, 200, 220, 161, 255, 95, 241, 211, 141, 81, 7, 150, 25, 25, 27, 162, 213,\n        80, 61, 12, 170, 50, 4, 154, 203, 252, 229, 119, 29, 202, 153, 50, 25, 126, 145, 245, 23,\n        136, 75, 29, 177,\n    ];\n    let hashed_message = [\n        13, 82, 120, 60, 76, 186, 215, 235, 175, 126, 185, 67, 252, 100, 143, 82, 130, 165, 32, 112,\n        68, 47, 193, 141, 141, 209, 109, 219, 47, 203, 175, 102,\n    ];\n\n    let addr = ecrecover(pub_key_x, pub_key_y, signature, hashed_message);\n    assert(addr == 0xf39fd6e51aad88f6f4ce6ab8827279cfffb92266);\n}\n","path":"/Users/kartik/projects/anoncast/packages/zk/circuits/lib/src/ecrecover/mod.nr"},"73":{"source":"use dep::std;\n\nuse dep::array_helpers;\n\nstruct PubKey {\n    pub_x: [u8; 32],\n    pub_y: [u8; 32],\n}\n\nfn split_uncompressed_pub_key(pub_key: [u8; 65]) -> ([u8; 32], [u8; 32]) {\n    let mut pub_key_x: [u8; 32] = [0; 32];\n    let mut pub_key_y: [u8; 32] = [0; 32];\n\n    for i in 0..32 {\n        pub_key_x[i] = pub_key[i + 1];\n        pub_key_y[i] = pub_key[i + 32 + 1];\n    }\n\n    (pub_key_x, pub_key_y)\n}\n\nimpl PubKey {\n    fn from_xy(pub_x: [u8; 32], pub_y: [u8; 32]) -> PubKey {\n        PubKey { pub_x, pub_y }\n    }\n\n    fn from_unified(pub_key: [u8; 64]) -> PubKey {\n        let (key_x, key_y) = array_helpers::split_u8_64(pub_key);\n\n        PubKey { pub_x: key_x, pub_y: key_y }\n    }\n\n    fn from_uncompressed(pub_key: [u8; 65]) -> PubKey {\n        assert(pub_key[0] == 0x04);\n        let (key_x, key_y) = split_uncompressed_pub_key(pub_key);\n\n        PubKey { pub_x: key_x, pub_y: key_y }\n    }\n\n    fn verify_sig(self, signature: [u8; 64], hashed_message: [u8; 32]) -> bool {\n        std::ecdsa_secp256k1::verify_signature(self.pub_x, self.pub_y, signature, hashed_message)\n    }\n\n    fn to_eth_address(self) -> Field {\n        let pub_key = array_helpers::u8_32_to_u8_64(self.pub_x, self.pub_y);\n        let hashed_pub_key = std::hash::keccak256(pub_key, 64);\n\n        let mut addr: Field = 0;\n        for i in 0..20 {\n            // shift left by 8 and add the new value\n            addr = (addr * 256) + hashed_pub_key[i + 12] as Field;\n        }\n\n        addr\n    }\n\n    fn ecrecover(self, signature: [u8; 64], hashed_message: [u8; 32]) -> Field {\n        assert(self.verify_sig(signature, hashed_message));\n\n        self.to_eth_address()\n    }\n}\n\n#[test]\nfn test_ecrecover_via_key() {\n    let pub_key_x = [\n        131, 24, 83, 91, 84, 16, 93, 74, 122, 174, 96, 192, 143, 196, 95, 150, 135, 24, 27, 79, 223,\n        198, 37, 189, 26, 117, 63, 167, 57, 127, 237, 117,\n    ];\n    let pub_key_y = [\n        53, 71, 241, 28, 168, 105, 102, 70, 242, 243, 172, 176, 142, 49, 1, 106, 250, 194, 62, 99,\n        12, 93, 17, 245, 159, 97, 254, 245, 123, 13, 42, 165,\n    ];\n    let signature = [\n        57, 17, 112, 239, 241, 30, 64, 157, 170, 50, 85, 145, 156, 69, 226, 85, 147, 164, 10, 82,\n        71, 93, 42, 132, 200, 220, 161, 255, 95, 241, 211, 141, 81, 7, 150, 25, 25, 27, 162, 213,\n        80, 61, 12, 170, 50, 4, 154, 203, 252, 229, 119, 29, 202, 153, 50, 25, 126, 145, 245, 23,\n        136, 75, 29, 177,\n    ];\n    let hashed_message = [\n        13, 82, 120, 60, 76, 186, 215, 235, 175, 126, 185, 67, 252, 100, 143, 82, 130, 165, 32, 112,\n        68, 47, 193, 141, 141, 209, 109, 219, 47, 203, 175, 102,\n    ];\n\n    let key = PubKey::from_xy(pub_key_x, pub_key_y);\n    assert(key.ecrecover(signature, hashed_message) == 0xf39fd6e51aad88f6f4ce6ab8827279cfffb92266);\n}\n","path":"/Users/kartik/projects/anoncast/packages/zk/circuits/lib/src/ecrecover/secp256k1.nr"},"79":{"source":"use crate::merkle::MerkleTree;\nuse crate::Calculator;\n\n/*\n * Transforms the key into into a big endian array of bits so that when determining the position\n * of a tree entry starting from the root node, the first array element to look at is the last.\n * @param key The key of a tree entry\n * @returns The path that determines the position of a key in the tree\n */\npub fn key_to_path(key: Field) -> [u1] {\n    key.to_be_bits()\n}\n\nimpl Calculator<Field> for MerkleTree {\n    fn calculate_root<let N: u32>(\n        self,\n        leaf: Field,\n        indexes: Field,\n        hash_path: [Field; N],\n    ) -> Field {\n        let index_bits: [u1; N] = indexes.to_le_bits();\n        let mut node = leaf;\n        for i in 0..hash_path.len() {\n            let sibling = hash_path[i];\n            if sibling != 0 {\n                let mut left = sibling;\n                let mut right = node;\n                if index_bits[i] == 0 {\n                    left = node;\n                    right = sibling;\n                }\n                node = (self.hasher)([left, right]);\n            }\n        }\n        node\n    }\n\n    /*\n     * Calculates two roots for a given leaf entry based on the passed array of siblings: one root\n     * for if the leaf entry was included in the tree and one for if the leaf entry was not included\n     * in the tree. This is useful for efficiently proving the membership of leaf entries for a\n     * tree while simultaneously modifying the tree.\n     * @param entry The key and value of an entry [k, v]\n     * @param siblings Contains the siblings from bottom to top\n     * @returns Two root nodes: the first one doesn't include entry, the second does\n     */\n    fn calculate_two_roots<let N: u32>(\n        self,\n        leaf: Field,\n        indexes: Field,\n        hash_path: [Field; N],\n    ) -> (Field, Field) {\n        let index_bits: [u1; N] = indexes.to_le_bits();\n\n        let mut root_with_leaf = leaf;\n        let mut root_without_leaf = 0;\n\n        for i in 0..hash_path.len() {\n            let sibling = hash_path[i];\n\n            if (sibling != 0) {\n                if i == hash_path.len() - 1 {\n                    root_without_leaf = hash_path[i];\n                }\n\n                if (index_bits[i] == 0) {\n                    root_with_leaf = (self.hasher)([root_with_leaf, sibling]);\n\n                    if (root_without_leaf != sibling) {\n                        root_without_leaf = (self.hasher)([root_without_leaf, sibling]);\n                    }\n                } else {\n                    root_with_leaf = (self.hasher)([sibling, root_with_leaf]);\n                    if (root_without_leaf != sibling) {\n                        root_without_leaf = (self.hasher)([sibling, root_without_leaf]);\n                    }\n                };\n            }\n        }\n        (root_without_leaf, root_with_leaf)\n    }\n}\n","path":"/Users/kartik/nargo/github.com/privacy-scaling-explorations/zk-kit.noirmain/packages/merkle-trees/src/merkle/tree.nr"},"84":{"source":"use crate::{MembershipProver, Modifier, MT_Creator};\nmod tests;\nmod tree;\n\nstruct MerkleTree {\n    hasher: fn([Field; 2]) -> Field,\n    pub root: Field,\n}\n\nimpl MT_Creator for MerkleTree {\n    fn default(root: Field, hasher: fn([Field; 2]) -> Field) -> Self {\n        Self { root, hasher }\n    }\n}\n\nimpl MembershipProver<Field, Field, Field> for MerkleTree {\n    fn membership<let N: u32>(self, leaf: Field, indexes: Field, hash_path: [Field; N]) {\n        let root = self.calculate_root(leaf, indexes, hash_path);\n        assert(self.root == root);\n    }\n}\n\nimpl Modifier<Field, Field, Field> for MerkleTree {\n    fn add<let N: u32>(&mut self, leaf: Field, indexes: Field, hash_path: [Field; N]) {\n        let (old, new) = self.calculate_two_roots(leaf, indexes, hash_path);\n\n        assert(old == self.root);\n        self.root = new;\n    }\n\n    fn delete<let N: u32>(&mut self, leaf: Field, indexes: Field, hash_path: [Field; N]) {\n        let (new, old) = self.calculate_two_roots(leaf, indexes, hash_path);\n        assert(old == self.root);\n        self.root = new;\n    }\n\n    fn update<let N: u32>(\n        &mut self,\n        leaf: Field,\n        old_leaf: Field,\n        indexes: Field,\n        hash_path: [Field; N],\n    ) {\n        let index_bits: [u1; N] = indexes.to_le_bits();\n\n        let mut old_parent: Field = old_leaf;\n        let mut new_parent: Field = leaf;\n\n        for i in 0..hash_path.len() {\n            let sibling = hash_path[i];\n            if sibling != 0 {\n                if index_bits[i] == 0 {\n                    new_parent = (self.hasher)([new_parent, sibling]);\n                    old_parent = (self.hasher)([old_parent, sibling]);\n                } else {\n                    new_parent = (self.hasher)([sibling, new_parent]);\n                    old_parent = (self.hasher)([sibling, old_parent]);\n                }\n            }\n        }\n        assert(old_parent == self.root);\n        self.root = new_parent;\n    }\n}\n","path":"/Users/kartik/nargo/github.com/privacy-scaling-explorations/zk-kit.noirmain/packages/merkle-trees/src/merkle.nr"}},"names":["main"],"brillig_names":["directive_integer_quotient","directive_invert"]}